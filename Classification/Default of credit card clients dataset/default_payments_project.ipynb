{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqkXuFGJr6Ap"
   },
   "source": [
    "<h1 style='text-align:center'>Default of credit card clients data set</h1>\n",
    "<p style='text-align:center'>This research aim at the case of customers default payments in Taiwan. Model predict accuracy of probability of default in the next month. <br>Default payment (Yes = 1, No = 0).</p>\n",
    "<p style='text-align:center'>The data used in the model come from - https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNUh5XbXr6Aq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115107,
     "status": "ok",
     "timestamp": 1567623273952,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "f0FnC7yAr6At",
    "outputId": "9f232829-c51a-47a0-9c2c-459e658467d6"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('cc.xls', header=1, index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1v1reutMr6Aw"
   },
   "source": [
    "<h2>Quick data overview and attributes explanation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1567608204042,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "KwaYJPN3r6Ax",
    "outputId": "e65f2f89-5ba9-4f51-9431-72c109e0c171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>-0.266200</td>\n",
       "      <td>-0.291100</td>\n",
       "      <td>51223.330900</td>\n",
       "      <td>49179.075167</td>\n",
       "      <td>4.701315e+04</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>1.133187</td>\n",
       "      <td>1.149988</td>\n",
       "      <td>73635.860576</td>\n",
       "      <td>71173.768783</td>\n",
       "      <td>6.934939e+04</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-165580.000000</td>\n",
       "      <td>-69777.000000</td>\n",
       "      <td>-1.572640e+05</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3558.750000</td>\n",
       "      <td>2984.750000</td>\n",
       "      <td>2.666250e+03</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22381.500000</td>\n",
       "      <td>21200.000000</td>\n",
       "      <td>2.008850e+04</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67091.000000</td>\n",
       "      <td>64006.250000</td>\n",
       "      <td>6.016475e+04</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>964511.000000</td>\n",
       "      <td>983931.000000</td>\n",
       "      <td>1.664089e+06</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LIMIT_BAL           SEX  ...       PAY_AMT6  default payment next month\n",
       "count    30000.000000  30000.000000  ...   30000.000000                30000.000000\n",
       "mean    167484.322667      1.603733  ...    5215.502567                    0.221200\n",
       "std     129747.661567      0.489129  ...   17777.465775                    0.415062\n",
       "min      10000.000000      1.000000  ...       0.000000                    0.000000\n",
       "25%      50000.000000      1.000000  ...     117.750000                    0.000000\n",
       "50%     140000.000000      2.000000  ...    1500.000000                    0.000000\n",
       "75%     240000.000000      2.000000  ...    4000.000000                    0.000000\n",
       "max    1000000.000000      2.000000  ...  528666.000000                    1.000000\n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMyngMt5r6A1"
   },
   "source": [
    "<h3>Attributes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YM54jOCBr6A2"
   },
   "source": [
    "<p><b>LIMIT_BAL:</b> Amount of the given credit - it includes both the individual consumer credit and his/her family (supplementary) credit.</p>  \n",
    "<p><b>SEX:</b> Gender (1 = male; 2 = female).</p>  \n",
    "<p><b>EDUCATION:</b> 1 = graduate school; 2 = university; 3 = high school; 4 = others</p>  \n",
    "<p><b>MARRIAGE:</b> Marital status (1 = married; 2 = single; 3 = others).</p>  \n",
    "<p><b>AGE:</b> Age (in years).</p>  \n",
    "<p><b>PAY_0 - PAY_6:</b> History of past payment from April to September 2005. PAY_0 = the repayment status in September 2005; PAY_2 = the repayment status in August, PAY_3 = the repayment status in Juli 2005; . . .;PAY_6 = the repayment status in April. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.</p>  \n",
    "<p><b>BILL_AMT1 - BILL_AMT6:</b> Amount of bill statement from April to September 2005. BILL_AMT1 = amount of bill statement in September; BILL_AMT2 = amount of bill statement in August; . . .; BILL_AMT6 = amount of bill statement in April.</p>  \n",
    "<p><b>PAY_AMT1 - PAY_AMT6:</b> Amount of previous payment from April to September 2005. PAY_AMT1 = amount paid in September; . . .; PAY_AMT6 - amount paid in April.</p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHGcgcO2r6A2"
   },
   "source": [
    "<p><b>Linear correlations between default payment in the next month and given attribute.</b><p>\n",
    "<p>The highest positive correlation occurs between the repayment status. Which is obvious, the most important is the status from the last month (September - PAY_0), because it is of the greatest importance in the context of October, for which we make a prediction.</p><p>Credit increase shows negative correlation, what also make sense. With the increase in the size of the loan, the risk of non-repayment on time increases.</p>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1567607975200,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "D7MvPhG4r6A3",
    "outputId": "368a56ea-6863-47a8-891f-a32bffbecf0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default payment next month    1.000000\n",
       "PAY_0                         0.324794\n",
       "PAY_2                         0.263551\n",
       "PAY_3                         0.235253\n",
       "PAY_4                         0.216614\n",
       "PAY_5                         0.204149\n",
       "PAY_6                         0.186866\n",
       "EDUCATION                     0.028006\n",
       "AGE                           0.013890\n",
       "BILL_AMT6                    -0.005372\n",
       "BILL_AMT5                    -0.006760\n",
       "BILL_AMT4                    -0.010156\n",
       "BILL_AMT3                    -0.014076\n",
       "BILL_AMT2                    -0.014193\n",
       "BILL_AMT1                    -0.019644\n",
       "MARRIAGE                     -0.024339\n",
       "SEX                          -0.039961\n",
       "PAY_AMT6                     -0.053183\n",
       "PAY_AMT5                     -0.055124\n",
       "PAY_AMT3                     -0.056250\n",
       "PAY_AMT4                     -0.056827\n",
       "PAY_AMT2                     -0.058579\n",
       "PAY_AMT1                     -0.072929\n",
       "LIMIT_BAL                    -0.153520\n",
       "Name: default payment next month, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix['default payment next month'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6ZvE3LEr6A6"
   },
   "source": [
    "<b>As the vast majority (over 99%) of the data from the LIMIT_BAL column are values below 500,000, I decided to delete all values above to have more consistent set of data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UHVISEar6A7",
    "outputId": "00009167-dda8-4662-a2ef-912a046c8e8c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL                     206\n",
       "SEX                           206\n",
       "EDUCATION                     206\n",
       "MARRIAGE                      206\n",
       "AGE                           206\n",
       "PAY_0                         206\n",
       "PAY_2                         206\n",
       "PAY_3                         206\n",
       "PAY_4                         206\n",
       "PAY_5                         206\n",
       "PAY_6                         206\n",
       "BILL_AMT1                     206\n",
       "BILL_AMT2                     206\n",
       "BILL_AMT3                     206\n",
       "BILL_AMT4                     206\n",
       "BILL_AMT5                     206\n",
       "BILL_AMT6                     206\n",
       "PAY_AMT1                      206\n",
       "PAY_AMT2                      206\n",
       "PAY_AMT3                      206\n",
       "PAY_AMT4                      206\n",
       "PAY_AMT5                      206\n",
       "PAY_AMT6                      206\n",
       "default payment next month    206\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 206 / 30000 = 0,69%\n",
    "data[data['LIMIT_BAL']>500000].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xc15T5Vsr6A9"
   },
   "outputs": [],
   "source": [
    "data.drop(data[data['LIMIT_BAL']>500000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cznszz8xr6BA"
   },
   "source": [
    "<h3>Data split into TRAINING, VALIDATION and TESTING sets.</h3>\n",
    "<ul>\n",
    "    <li><b>Training set</b> - I build my models using the data from the training set. Models learn from the inputs in this dataset.</li>\n",
    "    <li><b>Validation set</b> - Indicates how well my training set has performed.</li>\n",
    "    <li><b>Testing set</b> - Set which I will use at the end, to the final model performance validation. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FH-fDPUr6BB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# I start from creating testing set\n",
    "train_set, test_set = train_test_split(data, test_size=0.15, random_state=42)\n",
    "\n",
    "# then I divide train_set one more time to get validation set\n",
    "X = train_set.drop(\"default payment next month\", axis=1)\n",
    "y = train_set['default payment next month']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MWku-EQr6BE"
   },
   "source": [
    "<h2>Data standarization</h2><p>I scale the entire training set except labels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29YfNzFBr6BF"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1567623488758,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "5XObF-vWr6BI",
    "outputId": "d913eb1b-0651-450e-aaf6-bc80ba725f63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWEarp3Lr6BL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "scaled_training_features = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1567623491333,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "0i1-qBv5r6BO",
    "outputId": "e53e4aaa-4c32-44a0-c83e-d401bb197ba8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.677547</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>0.865486</td>\n",
       "      <td>2.766386</td>\n",
       "      <td>0.897684</td>\n",
       "      <td>-1.557135</td>\n",
       "      <td>-1.524976</td>\n",
       "      <td>-1.508003</td>\n",
       "      <td>-1.518717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687781</td>\n",
       "      <td>-0.684056</td>\n",
       "      <td>-0.671685</td>\n",
       "      <td>-0.662427</td>\n",
       "      <td>-0.339448</td>\n",
       "      <td>-0.259899</td>\n",
       "      <td>-0.305478</td>\n",
       "      <td>-0.308481</td>\n",
       "      <td>-0.313295</td>\n",
       "      <td>-0.287341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278993</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>-0.052684</td>\n",
       "      <td>0.897684</td>\n",
       "      <td>-1.557135</td>\n",
       "      <td>-0.695074</td>\n",
       "      <td>-0.663225</td>\n",
       "      <td>-0.643449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600607</td>\n",
       "      <td>-0.684056</td>\n",
       "      <td>-0.617061</td>\n",
       "      <td>-0.518967</td>\n",
       "      <td>-0.339448</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.305478</td>\n",
       "      <td>-0.101409</td>\n",
       "      <td>0.236019</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.076108</td>\n",
       "      <td>-1.232484</td>\n",
       "      <td>-1.084331</td>\n",
       "      <td>0.865486</td>\n",
       "      <td>1.031574</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.111805</td>\n",
       "      <td>0.134828</td>\n",
       "      <td>0.181554</td>\n",
       "      <td>0.231819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156854</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.278852</td>\n",
       "      <td>0.348019</td>\n",
       "      <td>-0.156914</td>\n",
       "      <td>-0.124911</td>\n",
       "      <td>-0.126209</td>\n",
       "      <td>-0.115376</td>\n",
       "      <td>-0.114100</td>\n",
       "      <td>-0.119546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.438412</td>\n",
       "      <td>-1.232484</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>-0.594813</td>\n",
       "      <td>1.784329</td>\n",
       "      <td>1.780746</td>\n",
       "      <td>1.794631</td>\n",
       "      <td>1.871111</td>\n",
       "      <td>1.982355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652450</td>\n",
       "      <td>0.729741</td>\n",
       "      <td>0.781364</td>\n",
       "      <td>0.794561</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>-0.088914</td>\n",
       "      <td>-0.126209</td>\n",
       "      <td>-0.108940</td>\n",
       "      <td>-0.114100</td>\n",
       "      <td>-0.119546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.713801</td>\n",
       "      <td>-1.232484</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>-0.052684</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.111805</td>\n",
       "      <td>0.134828</td>\n",
       "      <td>0.181554</td>\n",
       "      <td>0.231819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403949</td>\n",
       "      <td>0.448502</td>\n",
       "      <td>0.531509</td>\n",
       "      <td>0.566981</td>\n",
       "      <td>2.705338</td>\n",
       "      <td>-0.124146</td>\n",
       "      <td>-0.126209</td>\n",
       "      <td>-0.114347</td>\n",
       "      <td>-0.114100</td>\n",
       "      <td>-0.063055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL       SEX  EDUCATION  MARRIAGE       AGE     PAY_0     PAY_2  \\\n",
       "0  -0.677547  0.811370   0.184159  0.865486  2.766386  0.897684 -1.557135   \n",
       "1   0.278993  0.811370   0.184159 -1.052716 -0.052684  0.897684 -1.557135   \n",
       "2   1.076108 -1.232484  -1.084331  0.865486  1.031574  0.011039  0.111805   \n",
       "3  -0.438412 -1.232484   0.184159 -1.052716 -0.594813  1.784329  1.780746   \n",
       "4   1.713801 -1.232484   0.184159 -1.052716 -0.052684  0.011039  0.111805   \n",
       "\n",
       "      PAY_3     PAY_4     PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0 -1.524976 -1.508003 -1.518717  ...  -0.687781  -0.684056  -0.671685   \n",
       "1 -0.695074 -0.663225 -0.643449  ...  -0.600607  -0.684056  -0.617061   \n",
       "2  0.134828  0.181554  0.231819  ...   0.156854   0.183486   0.278852   \n",
       "3  1.794631  1.871111  1.982355  ...   0.652450   0.729741   0.781364   \n",
       "4  0.134828  0.181554  0.231819  ...   0.403949   0.448502   0.531509   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0  -0.662427 -0.339448 -0.259899 -0.305478 -0.308481 -0.313295 -0.287341  \n",
       "1  -0.518967 -0.339448  0.002203 -0.305478 -0.101409  0.236019  0.001155  \n",
       "2   0.348019 -0.156914 -0.124911 -0.126209 -0.115376 -0.114100 -0.119546  \n",
       "3   0.794561  0.104718 -0.088914 -0.126209 -0.108940 -0.114100 -0.119546  \n",
       "4   0.566981  2.705338 -0.124146 -0.126209 -0.114347 -0.114100 -0.063055  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training_data = pd.DataFrame(data=scaled_training_features, columns=X_train.columns)\n",
    "x_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxblO_FJr6BQ"
   },
   "source": [
    "<br><br><br><br><br><br><h1 style=\"text-align:center\">Training and evaluation of various classification models (with default settings) </h1>\n",
    "<h3 style=\"text-align:center\">Performance metrics</h3>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>True Positives (TP)</b></td><td>The total number of accurate predictions that were “positive.” This is the total number of correctly predicting default payments in the next month.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>False Positives (FP)</b></td><td>The total number of inaccurate predictions that were “positive.” This is the total number of incorrectly predicting default payments in the next month.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>True Negative (TN)</b></td><td>The total number of accurate predictions that were “negative.” This is the total number of correctly predicting payments on time.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>False Negative (FN)</b></td><td>The total number of inaccurate predictions that were “negative.” This is the total number of incorrectly predicting payments on time.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<ol>\n",
    "    <li><b>Accuracy</b> - (TP + TN)/(TP + FP + TN + FN)</li>\n",
    "    <li><b>Precision</b> - TP / (TP + FP)</li>\n",
    "    <li><b>Recall</b> - TP / (TP + FN)</li>\n",
    "    <li><b>F1-Score</b> - (2 * (Precision * Recall))/(Precision + Recall)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QHJs0PJr6BR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# confusion matrix looks like so:\n",
    "\n",
    "#                 |   Predict: 0   |   Predict: 1   |\n",
    "# ---------------------------------------------------\n",
    "# True Value: 0   |       TN       |       FP       |\n",
    "# ----------------|----------------|----------------|\n",
    "# True Value: 1   |       FN       |       TP       | \n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXw1Mookr6BU"
   },
   "source": [
    "<p><b>Standarization of validation set</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1567623498522,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "O6aBM5PRr6BV",
    "outputId": "9e80a43a-2ece-40b2-d788-a0dfd09e4a25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scaler = StandardScaler()\n",
    "valid_scaler.fit(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrEn_N75r6BX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "scaled_validation_features = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1567623500935,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "9X5aLzgzr6Ba",
    "outputId": "bedb9f53-1bc8-4d46-cd1a-66ba80b729f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996397</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>-1.084331</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>0.381019</td>\n",
       "      <td>-0.875605</td>\n",
       "      <td>-0.722665</td>\n",
       "      <td>-0.695074</td>\n",
       "      <td>-0.663225</td>\n",
       "      <td>-0.643449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683830</td>\n",
       "      <td>-0.679786</td>\n",
       "      <td>-0.667202</td>\n",
       "      <td>-0.657849</td>\n",
       "      <td>-0.323385</td>\n",
       "      <td>-0.248020</td>\n",
       "      <td>-0.289703</td>\n",
       "      <td>-0.291488</td>\n",
       "      <td>-0.295766</td>\n",
       "      <td>-0.272575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996397</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>0.381019</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.111805</td>\n",
       "      <td>0.134828</td>\n",
       "      <td>0.181554</td>\n",
       "      <td>0.231819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295599</td>\n",
       "      <td>0.439283</td>\n",
       "      <td>0.578474</td>\n",
       "      <td>0.688245</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>-0.034919</td>\n",
       "      <td>-0.006696</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.104181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.836970</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>1.452650</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>1.573702</td>\n",
       "      <td>1.784329</td>\n",
       "      <td>0.111805</td>\n",
       "      <td>0.134828</td>\n",
       "      <td>0.181554</td>\n",
       "      <td>0.231819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239359</td>\n",
       "      <td>0.297094</td>\n",
       "      <td>-0.177662</td>\n",
       "      <td>-0.356605</td>\n",
       "      <td>-0.162998</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.185965</td>\n",
       "      <td>-0.250550</td>\n",
       "      <td>-0.254267</td>\n",
       "      <td>0.915192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.235532</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>0.865486</td>\n",
       "      <td>-0.161110</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.111805</td>\n",
       "      <td>-0.695074</td>\n",
       "      <td>-0.663225</td>\n",
       "      <td>-0.643449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683112</td>\n",
       "      <td>-0.679026</td>\n",
       "      <td>-0.666404</td>\n",
       "      <td>-0.513799</td>\n",
       "      <td>-0.339448</td>\n",
       "      <td>-0.245860</td>\n",
       "      <td>-0.286894</td>\n",
       "      <td>-0.288462</td>\n",
       "      <td>0.255806</td>\n",
       "      <td>-0.052204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039858</td>\n",
       "      <td>-1.232484</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>-1.052716</td>\n",
       "      <td>0.489445</td>\n",
       "      <td>-0.875605</td>\n",
       "      <td>-0.722665</td>\n",
       "      <td>-0.695074</td>\n",
       "      <td>-0.663225</td>\n",
       "      <td>-0.643449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.631062</td>\n",
       "      <td>-0.642359</td>\n",
       "      <td>-0.636027</td>\n",
       "      <td>-0.620809</td>\n",
       "      <td>-0.132028</td>\n",
       "      <td>0.033925</td>\n",
       "      <td>-0.151426</td>\n",
       "      <td>-0.173308</td>\n",
       "      <td>-0.153939</td>\n",
       "      <td>0.085444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL       SEX  EDUCATION  MARRIAGE       AGE     PAY_0     PAY_2  \\\n",
       "0   0.996397  0.811370  -1.084331 -1.052716  0.381019 -0.875605 -0.722665   \n",
       "1   0.996397  0.811370   0.184159 -1.052716  0.381019  0.011039  0.111805   \n",
       "2  -0.836970  0.811370   1.452650 -1.052716  1.573702  1.784329  0.111805   \n",
       "3   1.235532  0.811370   0.184159  0.865486 -0.161110  0.011039  0.111805   \n",
       "4   0.039858 -1.232484   0.184159 -1.052716  0.489445 -0.875605 -0.722665   \n",
       "\n",
       "      PAY_3     PAY_4     PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0 -0.695074 -0.663225 -0.643449  ...  -0.683830  -0.679786  -0.667202   \n",
       "1  0.134828  0.181554  0.231819  ...   0.295599   0.439283   0.578474   \n",
       "2  0.134828  0.181554  0.231819  ...   0.239359   0.297094  -0.177662   \n",
       "3 -0.695074 -0.663225 -0.643449  ...  -0.683112  -0.679026  -0.666404   \n",
       "4 -0.695074 -0.663225 -0.643449  ...  -0.631062  -0.642359  -0.636027   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0  -0.657849 -0.323385 -0.248020 -0.289703 -0.291488 -0.295766 -0.272575  \n",
       "1   0.688245 -0.035225 -0.034919 -0.006696  0.013360  0.018697  0.104181  \n",
       "2  -0.356605 -0.162998 -0.111412 -0.185965 -0.250550 -0.254267  0.915192  \n",
       "3  -0.513799 -0.339448 -0.245860 -0.286894 -0.288462  0.255806 -0.052204  \n",
       "4  -0.620809 -0.132028  0.033925 -0.151426 -0.173308 -0.153939  0.085444  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation_data = pd.DataFrame(data=scaled_validation_features, columns=X_valid.columns)\n",
    "x_validation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOPjFnLNr6Bc"
   },
   "source": [
    "<h2>Naive Bayes Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWD4LQvir6Bd"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "# instantiation\n",
    "GNB = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXsgLSaer6Bg",
    "outputId": "af7adb51-45a9-4e81-9213-749b648b9ffd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "GNB.fit(x_training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlKsgbn0r6Bl"
   },
   "outputs": [],
   "source": [
    "# predicting\n",
    "GNB_predictions = GNB.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwP22HkYr6Bs",
    "outputId": "74a6b335-8a18-4021-fc8c-a9a0f43ea6a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2231  718]\n",
      " [ 324  526]]\n",
      "ACCURACY:  72.6 %\n",
      "PRECISION:  42.3 %\n",
      "RECALL:  61.9 %\n",
      "F1-score:  50.2 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, GNB_predictions))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, GNB_predictions),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, GNB_predictions),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, GNB_predictions),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, GNB_predictions),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaGpv01Lr6Bv"
   },
   "source": [
    "<h2>K Nearest Neighbors</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Wn-pqXbr6By"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJI_e5Q2r6B5"
   },
   "outputs": [],
   "source": [
    "knn_model.fit(x_training_data, y_train) # training\n",
    "knn_predictions = knn_model.predict(x_validation_data) # predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FA5eJxEr6B8",
    "outputId": "dd39e954-f2ab-4477-9292-4cc59f8dee28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2707  242]\n",
      " [ 570  280]]\n",
      "ACCURACY:  78.60000000000001 %\n",
      "PRECISION:  53.6 %\n",
      "RECALL:  32.9 %\n",
      "F1-score:  40.8 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, knn_predictions))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, knn_predictions),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, knn_predictions),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, knn_predictions),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, knn_predictions),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSieXsFVr6B-"
   },
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ora62PRYr6B-"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTMBZpY9r6CA",
    "outputId": "9866a6aa-c98c-42ed-b78c-1d153e38a8e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_reg_model.fit(x_training_data, y_train)\n",
    "log_reg_predictions = log_reg_model.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Z7iw40wr6CC",
    "outputId": "949e6061-a014-405c-9e93-f7d52871a431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2873   76]\n",
      " [ 651  199]]\n",
      "ACCURACY:  80.9 %\n",
      "PRECISION:  72.39999999999999 %\n",
      "RECALL:  23.400000000000002 %\n",
      "F1-score:  35.4 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, log_reg_predictions))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, log_reg_predictions),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, log_reg_predictions),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, log_reg_predictions),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, log_reg_predictions),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBFF1uZ-r6CE"
   },
   "source": [
    "<h2>Support Vector Machines</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YblOfNlqr6CF"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MD8Y62wLr6CI"
   },
   "outputs": [],
   "source": [
    "SVC_model.fit(x_training_data, y_train)\n",
    "SVC_predictions = SVC_model.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CS47Uzder6CM",
    "outputId": "f8f2b187-540c-44a4-99b8-3fd0c9c10302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2824  125]\n",
      " [ 570  280]]\n",
      "ACCURACY:  81.69999999999999 %\n",
      "PRECISION:  69.1 %\n",
      "RECALL:  32.9 %\n",
      "F1-score:  44.6 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, SVC_predictions))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, SVC_predictions),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, SVC_predictions),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, SVC_predictions),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, SVC_predictions),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2BXvzuFr6CO"
   },
   "source": [
    "<h2>Decision Tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChMM4Hybr6CP"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Duv1O9Rfr6CR"
   },
   "outputs": [],
   "source": [
    "tree_model.fit(x_training_data, y_train)\n",
    "tree_predictions = tree_model.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKkq4waRr6CU",
    "outputId": "5d1b3eab-3ad5-4846-fa04-dd8117ab7a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2429  520]\n",
      " [ 521  329]]\n",
      "ACCURACY:  72.6 %\n",
      "PRECISION:  38.800000000000004 %\n",
      "RECALL:  38.7 %\n",
      "F1-score:  38.7 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, tree_predictions))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, tree_predictions),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, tree_predictions),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, tree_predictions),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, tree_predictions),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y23MVXevr6CX"
   },
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agmKaJn3r6CX"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTf7D1pIr6Ca",
    "outputId": "f49084a7-f8c8-4aae-bd9d-80d5e7e72d6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "forest_model.fit(x_training_data, y_train)\n",
    "forest_predictions = forest_model.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tODlBf4Br6Cc",
    "outputId": "042c2563-c4cc-455a-fc04-09a37643619c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2787  162]\n",
      " [ 592  258]]\n",
      "ACCURACY:  80.2 %\n",
      "PRECISION:  61.4 %\n",
      "RECALL:  30.4 %\n",
      "F1-score:  40.6 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, forest_predictions))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, forest_predictions),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, forest_predictions),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, forest_predictions),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, forest_predictions),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PX4ghGBcr6Ce"
   },
   "source": [
    "<br><br><h1 style=\"text-align:center\">RESULTS SUMMARY</h1>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td><td><b>Naive Bayes Classifier</b></td><td><b>K Nearest Neighbors</b></td><td><b>Logistic Regression</b></td><td><b>Support Vector Machines</b></td><td><b>Decision Tree</b></td><td><b>Random Forest</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Accuracy</b></td><td>72.6 %</td><td>78.6 %</td><td>80.9 %</td><td>81.69 %</td><td>72.6 %</td><td>80.2 %</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Precision</b></td><td>42.3 %</td><td>53.6 %</td><td>72.39 %</td><td>69.1 %</td><td>38.8 %</td><td>61.4 %</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Recall</b></td><td>61.9 %</td><td>32.9 %</td><td>23.4 %</td><td>32.9 %</td><td>38.7 %</td><td>30.4 %</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>F1-score</b></td><td>50.2 %</td><td>40.8 %</td><td>35.4 %</td><td>44.6 %</td><td>38.7 %</td><td>40.6 %</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vcouI4Cr6Cf",
    "outputId": "3e89e671-7e8d-4832-b552-0aefdf4b6c56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16697\n",
       "1     4828\n",
       "Name: default payment next month, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LqyFwTY6r6Cg"
   },
   "source": [
    "<h3 style=\"text-align:center;\"><b>The results of the models are slightly different from each other. Now, I have to choose most promising of them and try to customize hyperparameters. However, before I do it, I need to get acquainted with the results presented and interpret them correctly.</b></h3>\n",
    "<p><b>Accuracy</b> seems like it could be the best method. It shows the percentage of correct predictions. However, accuracy only works when both possible outcomes are equal (or at least close to each other). In the training dataset, is significantly more accidents of timely payments than default payments (cell above). Thus, even if given model is very bad, it could achieve a high accuracy score, when it predict every payment as non-default. In these kind of situations, it makes it metric unreliable.</p>\n",
    "<p><b>Precision</b> is a measure that tells us what proportion of predictions that we classify as 'positive', actually is 'positive'. In our case, it show us how many payments that our model predict as default, will default indeed.</p>\n",
    "<p><b>Recall</b> is a measure that tells us what proportion of payments that actually are default was classified by the algorithm as default. </p>\n",
    "<p>Whether I should focus on precision or recall, depends largely on the business goal that my algorithm is supposed to achieve. In assessing whether the future payment will be made on time or not, it seems more important to correctly classify those payments that will actually defaulted. Even if model classify a given payment as default and this payment will make on time, it won't have a very negative effect, as opposed to the payment that will be classified as timely but in fact it won't (for instance a loan company may lose money if it lends it to someone who is unable to give it back). Therefore, I think recall is more important here.</p>\n",
    "<p><b>F1-score</b> get a single score that kind of represents both Precision and Recall by using a harmonic mean. Harmonic mean is kind of an average when x1 and x2 are equal. But when x1 and x2 are different, then it’s closer to the smaller number as compared to the larger number. So if you wanna get high F1-score, it's require maximialise both precision and recall simultaneously. </p>\n",
    "<p style=\"text-align:center;\"><b>Taking all this into account, I decided to choose recall as a main metric, since it best reflects the usefulness of the model in this particular business problem. I will take Support Vector Maschines and Decision Tree to further tuning.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DziU8zINr6Ch"
   },
   "source": [
    "<br><br><br><br><h1 style=\"text-align:center;\">Tuning Decision Tree model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1567608290080,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "ZsH4vhOir6Ci",
    "outputId": "7ef40bbc-0572-4c7a-cb41-edbeed931941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': None,\n",
      " 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint # show parameters used by model\n",
    "# parameters currently used in my decision tree model\n",
    "pprint(tree_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cW8ILvE4r6Ck"
   },
   "source": [
    "<h3>I will customize 4 main parameters of Decision Tree:</h3>\n",
    "<p><b>max_depth</b> - It indicates how deep the tree can be. The deeper tree, the more splits it has and it captures more information about the data.</p>\n",
    "<p><b>min_samples_split</b> - It represents the minimum number of samples required to split an internal node. This can vary between considering at least one sample at each node to all of the samples at each node.</p>\n",
    "<p><b>min_samples_leaf</b> - It represents the minimum number of samples required to be at a leaf node.</p>\n",
    "<p><b>max_features</b> - It represents the number of features to consider when looking for the best split.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Clc3KK-rr6Ck"
   },
   "source": [
    "Użyję metody przeszukiwania siatki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLTcPNhrr6Cl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgKoz0zUr6Co"
   },
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(start = 2, stop = 16, num = 8)]\n",
    "min_samples_split = [2, 4, 6, 8, 10, 12]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "max_features = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zESMCArr6Cv"
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'max_depth': max_depth, \n",
    "     'min_samples_split': min_samples_split, \n",
    "     'min_samples_leaf': min_samples_leaf, \n",
    "     'max_features': max_features}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-J7E2nler6Cy"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUlfmEnvr6C0"
   },
   "outputs": [],
   "source": [
    "decision_tree_tuned = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIb5Kbmpr6C5",
    "outputId": "e2314d77-abcd-42f3-fb3e-5afc562a31b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'max_depth': [2, 4, 6, 8, 10, 12, 14, 16], 'min_samples_split': [2, 4, 6, 8, 10, 12], 'min_samples_leaf': [2, 4, 6], 'max_features': [5, 10, 15, 20]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_tuned.fit(x_training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2srimU2Vr6C9",
    "outputId": "527c1257-f5ec-4cc0-d8b1-a1c21426e547"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 8}"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N069_xGIr6DD"
   },
   "outputs": [],
   "source": [
    "best_tree_model = decision_tree_tuned.best_estimator_\n",
    "best_tree_model_pred = best_tree_model.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDdOxuCer6DJ",
    "outputId": "90e35ef1-de1c-4d93-d9c6-21b98e805971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2810  139]\n",
      " [ 552  298]]\n",
      "ACCURACY:  81.8 %\n",
      "PRECISION:  68.2 %\n",
      "RECALL:  35.099999999999994 %\n",
      "F1-score:  46.300000000000004 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, best_tree_model_pred))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, best_tree_model_pred),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, best_tree_model_pred),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, best_tree_model_pred),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, best_tree_model_pred),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKIWk6opr6DL"
   },
   "source": [
    "<h3>Class weight manipulations - Decision Tree</h3>\n",
    "<p>There is improvement in some metrics (Accuracy + 9.2%, Precision + 29.4%), however, Racall, which is the most important for me, fell by 3.6%. To raise the Recall value, I experimented a bit with the 'class_weight' hyperparameter. As I mentioned earlier, the data from the training set are unbalanced in terms of the number of examples for a given class. The number of examples of timely payments predominates (in the ratio of 78% - 22%). The 'class_weight' hyperparameter can balance this difference by giving more weight to default payment cases.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxN-EA6lr6DL"
   },
   "outputs": [],
   "source": [
    "class_weights_list = [\n",
    "    {1 : 2}, {1 : 3}, {1 : 4}, {1 : 5}, {1 : 6}, {1 : 7}, {1 : 8}, {1 : 9}, {1 : 10}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgUcki5Vr6DN",
    "outputId": "59959253-43ec-43a8-e3c9-1ed53cbb0ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  {1: 2} RECALL:  0.4 PRECISION:  0.57 ACCURACY:  0.8\n",
      "Class weights:  {1: 3} RECALL:  0.54 PRECISION:  0.51 ACCURACY:  0.78\n",
      "Class weights:  {1: 4} RECALL:  0.57 PRECISION:  0.48 ACCURACY:  0.77\n",
      "Class weights:  {1: 5} RECALL:  0.74 PRECISION:  0.35 ACCURACY:  0.63\n",
      "Class weights:  {1: 6} RECALL:  0.77 PRECISION:  0.33 ACCURACY:  0.6\n",
      "Class weights:  {1: 7} RECALL:  0.82 PRECISION:  0.28 ACCURACY:  0.49\n",
      "Class weights:  {1: 8} RECALL:  0.82 PRECISION:  0.29 ACCURACY:  0.51\n",
      "Class weights:  {1: 9} RECALL:  0.9 PRECISION:  0.27 ACCURACY:  0.44\n",
      "Class weights:  {1: 10} RECALL:  0.92 PRECISION:  0.26 ACCURACY:  0.39\n"
     ]
    }
   ],
   "source": [
    "# I create models with best parameters and manipulate class_weight parameter:\n",
    "for i in range(len(class_weights_list)):\n",
    "    drzewo = DecisionTreeClassifier(max_depth=4, \n",
    "                                    max_features=10, \n",
    "                                    min_samples_leaf=2, \n",
    "                                    min_samples_split=8, \n",
    "                                    class_weight=class_weights_list[i])\n",
    "    drzewo.fit(x_training_data, y_train)\n",
    "    pred = drzewo.predict(x_validation_data)\n",
    "    print(\"Class weights: \", class_weights_list[i], \n",
    "          \"RECALL: \", round(recall_score(y_valid, pred),2),\n",
    "          \"PRECISION: \", round(precision_score(y_valid, pred),2),\n",
    "          \"ACCURACY: \", round(accuracy_score(y_valid, pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9QmE1BIr6DP"
   },
   "source": [
    "Recall increase when weight of the default payment class increase, but in the same time precision and accuracy go down. The final choice of model parameters depends on the specific bussines requirements. You have to answer the question, how many incorrect classifications of timely payments you can afford to correctly find those actually defaulted, that can affect on your business. The point is to find trade-off between recall and precision. As I mentioned before, I focus here on recall so I could consider models with class weight 1:9. It gives me 90% recall and almost 50% accuracy. I am not satisfied of that but probably I can't get anything more with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMMekgEVr6DQ"
   },
   "source": [
    "<br><br><h3>Class weight manipulations - SVM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>I didn't do grid search for SVM, because it takes a long time and the result would probably not improve significantly. I just tried different class weights.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552524,
     "status": "ok",
     "timestamp": 1567624113409,
     "user": {
      "displayName": "Tomasz Kościelniak",
      "photoUrl": "",
      "userId": "17177696409305527274"
     },
     "user_tz": -120
    },
    "id": "yPpifpllr6Da",
    "outputId": "3bfe7e6f-5aad-4ddb-d15d-7561bc1b59b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight:  {1: 2} RECALL:  0.42 PRECISION:  0.58 ACCURACY:  0.8\n",
      "Class weight:  {1: 3} RECALL:  0.49 PRECISION:  0.51 ACCURACY:  0.78\n",
      "Class weight:  {1: 4} RECALL:  0.63 PRECISION:  0.37 ACCURACY:  0.67\n",
      "Class weight:  {1: 5} RECALL:  0.77 PRECISION:  0.29 ACCURACY:  0.52\n",
      "Class weight:  {1: 6} RECALL:  0.96 PRECISION:  0.24 ACCURACY:  0.32\n",
      "Class weight:  {1: 7} RECALL:  0.99 PRECISION:  0.23 ACCURACY:  0.26\n",
      "Class weight:  {1: 8} RECALL:  0.99 PRECISION:  0.23 ACCURACY:  0.24\n",
      "Class weight:  {1: 9} RECALL:  1.0 PRECISION:  0.23 ACCURACY:  0.23\n",
      "Class weight:  {1: 10} RECALL:  1.0 PRECISION:  0.22 ACCURACY:  0.22\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_weights_list)):\n",
    "    svc_model = SVC(C=1, \n",
    "                    kernel='poly', \n",
    "                    gamma=1,\n",
    "                    degree=1,\n",
    "                    class_weight=class_weights_list[i])\n",
    "    svc_model.fit(x_training_data, y_train)\n",
    "    pred = svc_model.predict(x_validation_data)\n",
    "    print(\"Class weight: \", class_weights_list[i], \n",
    "          \"RECALL: \", round(recall_score(y_valid, pred),2),\n",
    "          \"PRECISION: \", round(precision_score(y_valid, pred),2),\n",
    "          \"ACCURACY: \", round(accuracy_score(y_valid, pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Class weights above 1 to 6 achieve close to 100% recall score. This is due to the almost complete elimination of False Negativ prediction. Model too often predict that payment is default, even if it's not true. However, as I said earlier, in this specific bussines problem it's better to make mistake by classifing timely payment as default than miss real default.</b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C=1, kernel='poly', gamma=1, degree=1, class_weight={1:6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight={1: 6}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma=1, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(x_training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc_model.predict(x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 385 2564]\n",
      " [  33  817]]\n",
      "ACCURACY:  31.6 %\n",
      "PRECISION:  24.2 %\n",
      "RECALL:  96.1 %\n",
      "F1-score:  38.6 %\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, pred))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y_valid, pred),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y_valid, pred),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y_valid, pred),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y_valid, pred),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>As you can see above in the confusion matrix, the False Negative case occurred only 33 times.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><h2 style=\"text-align:center\">FINAL MODEL TESTING USING TEST SET</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE\n",
      "[[ 981 2554]\n",
      " [  83  852]]\n",
      "ACCURACY:  41.0 %\n",
      "PRECISION:  25.0 %\n",
      "RECALL:  91.10000000000001 %\n",
      "F1-score:  39.300000000000004 %\n",
      "\n",
      "\n",
      "SVM\n",
      "[[ 493 3042]\n",
      " [  42  893]]\n",
      "ACCURACY:  31.0 %\n",
      "PRECISION:  22.7 %\n",
      "RECALL:  95.5 %\n",
      "F1-score:  36.7 %\n"
     ]
    }
   ],
   "source": [
    "# test set split into features(X) and labels(y)\n",
    "X = test_set.drop('default payment next month', axis=1)\n",
    "y = test_set['default payment next month']\n",
    "\n",
    "# scaling features\n",
    "scaler.fit(X)\n",
    "test_set_feat_scaled = scaler.transform(X)\n",
    "\n",
    "# predictions\n",
    "TREE_pred = tree_model.predict(test_set_feat_scaled)\n",
    "SVC_pred = svc_model.predict(test_set_feat_scaled)\n",
    "\n",
    "# results\n",
    "print(\"DECISION TREE\")\n",
    "print(confusion_matrix(y, TREE_pred))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y, TREE_pred),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y, TREE_pred),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y, TREE_pred),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y, TREE_pred),3)*100, \"%\")\n",
    "print('\\n')\n",
    "print(\"SVM\")\n",
    "print(confusion_matrix(y, SVC_pred))\n",
    "print(\"ACCURACY: \", round(accuracy_score(y, SVC_pred),3)*100, \"%\")\n",
    "print(\"PRECISION: \", round(precision_score(y, SVC_pred),3)*100, \"%\")\n",
    "print(\"RECALL: \", round(recall_score(y, SVC_pred),3)*100, \"%\")\n",
    "print(\"F1-score: \", round(f1_score(y, SVC_pred),3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Summary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The machine learning models did not bring enough satisfactory results. In description of the dataset stated that attempts were made to solve this problem on 6 different ML models and only an artificial neural network gived satisfactory results. Therefore, I'll try to do this task once again, using the neural network.</b> "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
